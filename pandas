#1. map함수 쓰는법
df['column'].map(lambda x: x 에 할 연산) #column지정안하면 이상하게 나올 수 있음. series 용이라.
e.g.
#빈 리스트인지 확인
df['Genre'].map(lambda x : x == "[]") 
하면 series 값 별로 lambda함수를 연산해줌.

#2. DataFrame합치는 pd.concat()
#axis 방향
pd.concat(df1,df2,axis = 1) #옆으로 붙임
pd.concat(df1,df2,axis = 0) #밑에다 붙임.
first argument must be an iterable of pandas objects, you passed an object of type "DataFrame" 이 뜰것. 리스트로 넣어줘야하기 때문.

  #맞는 코드
  pd.concat([df1,df2],axis = 1) #옆으로 붙임
  pd.concat([df1,df2],axis = 0) #밑에다 붙임.

# * pd.concat([],axis = 1)로 합칠 때 합치는 기준은 index임.  
# 물론 pd.concat([df1,df2],ignore_index = True,axis = 1) 옵션을 주면 말그대로 옆으로 그냥 갖다붙임. 그러나 컬럼 이름이 0,1,2,..로 변해버림
# = pd.concat([df_5, df_6], keys=['df_5', 'df_6'], names=['df_name', 'row_number']) 같이 names = 를 통해 컬럼 이름을 주면 됨.



출처: https://rfriend.tistory.com/256 [R, Python 분석과 프로그래밍의 친구 (by R Friend)]


#3. 열 삭제 df.drop()
df.drop(['컬럼1','컬럼2'],axis = 1) #axis 지정안해주면 컬럼 못찾겠다 에러날 수도.  
#이대로 놓는다고 df가 변하지는 않음.
df = df.drop(['컬럼1','컬럼2'],axis = 1) #까지 해줘야 함.

#4. 행삭제
df.drop([행인덱스,행인덱스])

5.행 수 세는법
len(df[df['Label'] == 'Benign']) 이렇게 len으로  특정 컬럼('Label')의 행 갯수 셀 수 있음.

6. 판다스 inplace의 의미
inplace 옵션에 True를 주면 또 다른 객체를 반환하지 않고 기존 객체를 수정 (ex. df.fillna(inplace=True) )
즉, 다시 df = 내가 원한 연산 이런거 안해줘도 됨.
출처: https://sacko.tistory.com/18 [데이터 분석하는 문과생, 싸코]

#7. Df에 새로운 행 추가.
팬더는 완전히 채워진 ‘데이터 프레임’을로드하도록 설계되었습니다.
그치만 append()메소로 사전의 값을 행으로 직접 가져 와서 팬더dataframe에 추가 할 수 있습니다.
df = df.append({'컬럼':값},colimns = [],ignore_index = True)
https://www.delftstack.com/ko/howto/python-pandas/how-to-add-one-row-to-pandas-dataframe/

#8. df에서 index를 새로운 컬럼으로 만들기.
df.reset_index() #하면됨.

#9. def안에서 df를 어쩔 수 없이 할당해야될때.

def scale_log(col_name):
  global df 
  # 밑에 drop을 사용하려면 필연적으로 df = 식 처럼 df에 할당해줘야함. 그런데 그러면 def에서 전역/지역변수 문제 발생.def안에 변수를 할당시키면 지역변수로 생각하기 때문.
  # global 해주면 말끔히 해결.
  
  log_col_name = 'log_' + col_name
  df[log_col_name] = df[col_name].apply(lambda x: np.log(x))
  df = df.drop(col_name, axis = 1) #이거때매그럼.
  return df[log_col_name]

#10. df에 = 으로 할당시 주의점.
df1[['new_col'] = df2['col'] 하면 concat처럼 눈에보이는 순서를 간직하고 붙는게 아닌, index에 맞게 붙음. 따라서 그냥 = 로 할당해주면 안됨.
df1.reset_index() 활용.

#11 pandas sum  #df.sum의 형태.
df.sum() #세로별합
df.sum(axis = 0) # 세로합

df.sum(axis = 1) #가로합

#12. datetime, 시간 정보 전처리.
df = pd.DataFrame([20201101025616])
pd.to_datetime(df['해당컬럼'],format ='%Y%m%d%H%M%S') # format으로 형태를 지정해줄 수 있음.

df = pd.DataFrame({'Birth':['2019-01-01 09:10:00']}) #이런형태라면 아래처럼
df['Birth'] = pd.to_datetime(df['Birth'], format='%Y-%m-%d %H:%M:%S', errors='raise')

#참고
#https://m.blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221603462366&proxyReferer=https:%2F%2Fwww.google.com%2F

#12 -2 datetime 연산

#1)  pd.to_datetime(df컬럼) #datetime타입으로 바꿔주기 
df['date'] = pd.to_datetime(df['date'])

#2) pd.DateOffset(weeks/months/days = n)으로 연산가능
released_date_code['Released_date'][0] + pd.DateOffset(weeks=1)

https://tariat.tistory.com/631 참조

#12 - 3 datetime pd.read_csv읽어올때 인식도 가능
df = pd.read_csv('diabetes.csv',parse_dates=["date"]) # 가령 이런식으로 date가 있는 컬럼을 지정해줘도 나중에
# 연도 컬럼 전처리
df["year"] = df['date'].dt.year
df["month"] = df['date'].dt.month
df["hour"] = df['date'].dt.hour
# 이런거 가능.


#13. pandas 행 개수 세기
len(Series) #하면 간단히 세기 가능.

#14. merge 
pd.merge(df_left,df_right,on = 'col name',how = 'inner'/'outer/left/right')

#15. apply로 여러 컬럼 값 바꾸기
df['NewCol'] = df.apply(lambda x: segmentMatch(x['TimeCol'], x['ResponseCol']), axis=1)
#이런식으로 df.apply(lambda x: func(x['col1']x['col2']),axis = 1) 로 넣으면 됨. axis = 1 은 row 별로 돈다는 뜻. 

#apply with 하나의 컬럼.
#내가 익숙했던 apply, lambda는 아래와 같았다.
df['new col'] = df['col'].apply(lambda x: func(x)) # 하면 df에서 col의 row를 돌며 func를 적용함. 
#그런데! #15와같이 쓸떄 axis 의 default 는 axis = 0 임. 열별로 도는 것. 따라서 조심해야함. 

#16 1 상위 값 몇개 뽑기. max

#시리즈.nlargest(n, keep='first')

n : 상위 몇개까지 나타낼 것인가
keep='first' : 동등한 값이 있다면 제일 먼저 나온 값을 보여준다.

시리즈의 경우엔 컬럼을 명시할 필요 없다.

#데이터프레임.nlargest(n, columns, keep='first')

데이터프레임의 경우 우선 순위에 따라 컬럼을 명시해 줄 수 있다.

# #16 1 상위 값 몇개 뽑기. min
.smallest(n)

#16 df.isin() #여러개 bool, 색인 쓰고싶으면 df.isin([원소1,원소2])활용!
df.isin(Series) #series도 들어가기 가능

#17 pandas boolean 다루기
df
>>
  0
0	False
1	False
2	False
3	False
4	False
...	...
4732	False
4733	False
4734	False
4735	False
4736	False
4737 rows × 1 columns
이거로 다른 df에서 True인 레코드만 뽑아내기불가.
이유: Series가 아님. 위에 타입은 dataframe임. 
0	NaN
1	NaN
2	NaN
..
막 이렇게 뜰것.

#18. Series에서 평균값 구하기 Series.mean()
Series에게 .average()는 통하지 않음. mean()으로 해야함.
cf) python, numpy
#python --> sum(list)/len(list) # average함수 
#numpy --> array.mean() np.array([1,2,3]).mean() --> 2.0

#19. .count()
 count()는 Null 값이 아닌 행(count Non-null rows)만 세며,
출처: https://rfriend.tistory.com/450 [R, Python 분석과 프로그래밍의 친구 (by R Friend)]

#20. Instead of using double indexing, Use .loc
df['a_col']['b_col'] 해서 자료 접근하면 result는 같음. 그런데 값을 바꾸지는 못함. (이유는 아래)
https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

#21. 행 삽입하는 코드

idx = 9 ## 원하는 인덱스

temp1 = ev_df[ev_df.index < idx]
temp2 = ev_df[ev_df.index >= idx]
ev_df = temp1.append(r12,ignore_index=True).append(temp2, ignore_index=True)

#22. 결측치 있는 행, 열 제거
df.dropna(axis = 0) # 행 제거
df.dropna(axis = 1) # 열 제거

#23. 리스트 포함한 df를 to_csv로 저장하면 안돼. str로 깨짐.
pickle 로 저장하면 됨

# 24. groupby
group = df['출력할col'].groupby(abalone['그룹지을col'])
group.sum group.mean group.size 모두 

출처: https://rfriend.tistory.com/383 [R, Python 분석과 프로그래밍의 친구 (by R Friend)]
https://rfriend.tistory.com/383

#25. 한번에 df 컬럼들 type 바꾸기
df.astype('float') #모든열
df.astype({'컬럼명':dtype}) #특정열의 data type바꾸기

#26. 실수로 리스트 csv로 저장. string to list
import ast
x = '[ "A","B","C" , "D"]'

x = ast.literal_eval(x)
x #리스트로 잘 바뀜

#27 날짜컬럼 처리
pd.to_datetime(df['date컬럼']) #해당 date 컬럼을 datetime으로 인식

#tip! date컬럼 기준으로 merge하면 date컬럼 인식 다시 해줘야함.
df_merged = pd.merge(df1,df2,on = 'date', how = 'left') #후에 datetime으로 바꿔주기
df_merged['date'] = pd.to_datetime(df_merged['date'])


#28. One-hot Encoding
one_hot_result_1=pd.get_dummies(hd['범주형변수 컬럼']) #N인코딩
one_hot_result_1=pd.get_dummies(hd['범주형변수 컬럼'],drop_first= True) # N-1인코딩
